import{_ as i,c as e,a as n,o as a}from"./app-RmE5kr10.js";const l={};function t(r,s){return a(),e("div",null,s[0]||(s[0]=[n(`<p>本模块包含两个紧密协作的核心子系统：</p><ol><li><strong>智能 Pipeline 推荐 (Recommendation)</strong>：负责“从 0 到 1”，将自然语言需求转化为完整的可执行 Pipeline。</li><li><strong>Pipieline 迭代优化 (Refinement)</strong>：负责“从 1 到 N”，基于用户反馈对现有 Pipeline 结构进行微调。</li></ol><h2 id="第一部分-pipeline-推荐-pipeline-recommendation" tabindex="-1"><a class="header-anchor" href="#第一部分-pipeline-推荐-pipeline-recommendation"><span>第一部分：Pipeline 推荐 (Pipeline Recommendation)</span></a></h2><h3 id="_1-概述" tabindex="-1"><a class="header-anchor" href="#_1-概述"><span>1. 概述</span></a></h3><p><strong>Pipeline 推荐</strong> 是 DataFlow-Agent 的核心编排引擎。它能够理解复杂的业务需求，自动拆解任务步骤，从算子库中检索最佳组件，规划数据流向，并生成可执行的 Python 代码。</p><p>该系统具备自我修复能力：在生成代码执行失败时，Agent 会主动查阅算子源码文档，分析错误原因并修正代码，直至执行成功。</p><h3 id="_2-系统架构" tabindex="-1"><a class="header-anchor" href="#_2-系统架构"><span>2. 系统架构</span></a></h3><p>该功能由 <code>dataflow_agent/workflow/wf_pipeline_recommend_extract_json.py</code> 编排，形成一个包含多级智能体的有向图。以下是详细的节点职责说明：</p><h4 id="_2-1-分析与规划阶段" tabindex="-1"><a class="header-anchor" href="#_2-1-分析与规划阶段"><span>2.1 分析与规划阶段</span></a></h4><ol><li><strong>Classifier Node</strong><ol><li><strong>职责</strong>: 读取少量数据样例，识别数据类型和业务领域。这决定了后续推荐算子的倾向性。</li><li><strong>输入</strong>: <code>state.request.json_file</code> (数据文件路径)。</li><li><strong>输出</strong>: <code>state.category</code>。</li></ol></li><li><strong>Target Parser Node</strong><ol><li><strong>核心任务 (What it does)</strong>: 充当业务分析的角色。它不直接生成代码，而是将用户模糊的需求转化为逻辑严密的步骤。</li><li><strong>输入</strong>: 用户的自然语言需求（例如：“过滤掉pdf中长度小于10的文本，然后去重，最后提取关键词”）。</li><li><strong>LLM 思考</strong>: 将需求拆解为标准的、符合数据处理逻辑的步骤列表（如 <code>[&quot;读取解析pdf成纯文本&quot;, &quot;过滤掉长度小于10个字符的文本数据&quot;, &quot;对文本数据进行去重处理，移除重复内容&quot;,&quot;从文本数据中提取关键词&quot;]</code>）。</li><li><strong>后续动作</strong>: 利用拆解出的步骤描述，去算子向量数据库中检索最相似的物理算子，形成<strong>候选算子池</strong>，供下一阶段使用。</li></ol></li><li><strong>Recommender Node</strong><ol><li><strong>核心任务</strong>: 负责将散乱的候选算子变成有序的执行方案。</li><li><strong>输入</strong>: <ul><li><code>target</code>: 用户的原始需求。</li><li><code>sample</code>: 数据样本（了解数据特征，如字段名、格式）。</li><li><code>split_ops</code>: 上一步 <code>target_parser</code> 通过 RAG 检索出来的候选算子列表及其功能描述。</li></ul></li><li><strong>LLM</strong> <strong>思考</strong>: <ul><li><strong>逻辑排序</strong>: 每个阶段不是只能有一个算子，而是遵循 “需求”</li><li><strong>数据兼容性</strong>: 若某算子需要字段“X”但样例数据中不存在，必须确保在它之前有算子创建该字段</li><li><strong>查漏补缺</strong>: 现有算子能满足需求吗？如果不行，需要插入一个万能的 <code>PromptedGenerator</code></li></ul></li><li><strong>输出</strong>: 一个有序的算子名称列表以及推荐理由，如</li></ol><div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-json"><span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">{</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">   &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">ops</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> [</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Text2SQLQuestionGenerator</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">SQLExecutionFilter</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">SQLConsistencyFilter</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">SQLVariationGenerator</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Text2SQLQuestionGenerator</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Text2SQLPromptGenerator</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Text2SQLCoTGenerator</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">ReasoningQuestionSolvableSampleEvaluator</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">SQLComponentClassifier</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">      &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">PromptedGenerator</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">   ],</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">   &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">reason</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">该流水线设计旨在满足用户的所有需求。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   1. 首先，通过 Text2SQLQuestionGenerator 解析 SQL 数据文件并提取 SQL 语句和对应的自然语言问题。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   2. 接着，使用 SQLExecutionFilter 在数据库中执行 SQL 语句以验证其有效性。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   3. 然后，使用 SQLConsistencyFilter 进行一致性过滤，确保 SQL 语句与其对应的自然语言问题一致。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   4. 接下来，使用 SQLVariationGenerator 对有效的 SQL 语句进行扩增，包括替换数值、提高语法难度和更改书写方式。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   5. 随后，使用 Text2SQLQuestionGenerator 基于扩增后的 SQL 语句生成对应的自然语言问题。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   6. 接着，使用 Text2SQLPromptGenerator 生成 Prompt 提示词内容，并通过 Text2SQLCoTGenerator 生成思维链推理过程。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   7. 然后，使用 ReasoningQuestionSolvableSampleEvaluator 对生成的数据进行分类，评估大模型解决问题的难度，并使用 SQLComponentClassifier 评估 SQL 组成部分的难度。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   8. 最后，使用 PromptedGenerator 输出合成的 SQL 数据及其对应的自然语言问题和推理过程，以确保所有需求得到满足。</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h4 id="_2-2-构建与执行阶段" tabindex="-1"><a class="header-anchor" href="#_2-2-构建与执行阶段"><span>2.2 构建与执行阶段</span></a></h4><ol><li><strong>Builder Node</strong><ol><li><strong>职责</strong>: 将推荐方案（JSON）转化为实际的 Python 代码文件，并启动子进程执行该代码。</li><li><strong>机制</strong>: 支持创建子进程执行代码，捕获标准输出 (stdout) 和标准错误 (stderr)。</li><li><strong>输出</strong>: <code>state.execution_result</code> (Success/Fail 状态及日志)。</li></ol></li></ol><h4 id="_2-3-自动修复闭环" tabindex="-1"><a class="header-anchor" href="#_2-3-自动修复闭环"><span>2.3 自动修复闭环</span></a></h4><p>当 <code>builder</code> 执行失败且 <code>need_debug=True</code> 时，进入此循环：</p><ol><li><p><strong>Debugger Node</strong></p><ul><li><strong>职责</strong>: 分析错误堆栈 (<code>error_trace</code>) 和当前代码，判断错误类型（参数错误、逻辑错误等）。</li></ul></li><li><p><strong>Info Requester Node</strong></p><ul><li><strong>职责</strong>: 这是一个主动学习节点。如果 Debugger 认为信息不足，它会调用工具读取相关算子的<strong>源代码</strong>或<strong>文档</strong>，获取上下文信息。</li></ul></li><li><p><strong>Rewriter Node</strong></p><ol><li><strong>职责</strong>: 综合错误日志和 InfoRequester 查到的源码知识，生成修复后的完整代码。</li><li><strong>流转</strong>: 修复后的代码会再次送入 <code>builder</code> 进行测试，直到成功或达到最大重试次数 (<code>max_debug_rounds</code>)。</li></ol></li></ol><h4 id="_2-4-输出阶段" tabindex="-1"><a class="header-anchor" href="#_2-4-输出阶段"><span>2.4 输出阶段</span></a></h4><ul><li><p><strong>Exporter Node</strong></p><ul><li><strong>职责</strong>: 执行成功后，整理最终的 Pipeline 信息、代码路径及数据样例，格式化输出给用户。</li></ul></li></ul><h3 id="_3-使用指南" tabindex="-1"><a class="header-anchor" href="#_3-使用指南"><span>3. 使用指南</span></a></h3><p>本功能提供 <strong>图形界面 (Gradio UI)</strong> 和 <strong>命令行脚本</strong> 两种使用方式。</p><h4 id="_3-1-图形界面" tabindex="-1"><a class="header-anchor" href="#_3-1-图形界面"><span>3.1 图形界面</span></a></h4><p>代码位于 <code>gradio_app/pages/pipeline_rec.py</code>，适合交互式探索和快速验证。启动 Web 界面：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">python gradio_app</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">/</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">app</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>访问 <code>http://127.0.0.1:7860</code> 开始使用</p><ol><li><p><strong>配置输入</strong>：</p><ol><li>在&quot;目标描述&quot;框中输入您的需求</li><li>输入需要处理jsonl文件</li><li>配置 API 信息（URL、Key、模型）</li><li>(可选)配置嵌入模型和调试选项</li><li>选择是否需要自动更新向量索引（如果出现算子不在注册机里，则需要勾选）</li><li>选择是否使用debug模式（debug模式会自动运行生成的 Pipeline 代码，直到最大迭代轮次）</li></ol></li><li><p><strong>生成pipeline</strong>：</p><p>点击 <strong>&quot; Generate Pipeline&quot;</strong>。</p></li><li><p><strong>结果查看</strong>：</p><ol><li><strong>Pipeline Code</strong>: 查看最终生成的pipeline 代码</li><li><strong>Execution Log</strong>: 查看执行的日志信息</li><li><strong>Agent Results:</strong> 各个 Agent 节点的详细执行结果，包含推荐的算子列表、构建过程等</li><li><strong>Pipeline JSON:</strong> 生成的Pipeline拓扑结构JSON，包含算子节点列表和节点间连接关系</li></ol></li></ol><h4 id="_3-2-脚本调用" tabindex="-1"><a class="header-anchor" href="#_3-2-脚本调用"><span>3.2 脚本调用</span></a></h4><p>对于自动化任务或批量生成，推荐直接修改并运行 <code>script/run_dfa_pipeline_recommend.py</code>。</p><h5 id="_1-修改配置" tabindex="-1"><a class="header-anchor" href="#_1-修改配置"><span>1. 修改配置</span></a></h5><p>打开 <code>script/run_dfa_pipeline_recommend.py</code>，在文件顶部的配置区域进行修改。</p><p><strong>API 配置</strong></p><ul><li><strong><code>CHAT_API_URL</code></strong>: LLM 服务地址</li><li><strong><code>api_key</code></strong>: 访问密钥（使用环境变量 DF_API_KEY）</li><li><strong><code>MODEL</code></strong>: 模型名称，默认 gpt-4o</li></ul><p><strong>任务配置</strong></p><ul><li><strong><code>TARGET</code></strong>: 用自然语言详细描述您的数据处理需求 <ul><li>示例：<code>&quot;请帮我编排一个专门用于大规模预训练数据清洗的流水线，涵盖从去重、改写到质量过滤的全过程&quot;</code></li></ul></li><li><strong><code>TEST_JSON_REL_PATH</code></strong>: 用于测试 Pipeline 的数据文件的相对路径 <ul><li>格式：每行一个 JSON 对象</li><li>默认：<code>{项目根目录}/tests/test.jsonl</code></li></ul></li></ul><p><strong>调试配置</strong></p><ul><li><strong><code>NEED_DEBUG</code></strong>: 是否启用自动调试和修复 <ul><li><strong><code>True</code></strong>: Agent 生成代码后会立即尝试运行。如果报错（如 <code>ImportError</code>, <code>KeyError</code>），它会启动 Debugger Agent 分析错误堆栈，自动修改代码并重试</li><li><strong><code>False</code></strong>：生成代码运行后立即结束，不进行自动调试和修复</li></ul></li><li><strong><code>MAX_DEBUG_ROUNDS</code></strong>: 最大自动修复次数，默认 5 次</li></ul><p><strong>文件配置</strong></p><ul><li><strong><code>CACHE_DIR</code></strong>: 结果输出目录。生成的 pipeline 代码、执行的日志、中间结果等都会保存在这里</li></ul><h5 id="_2-运行脚本" tabindex="-1"><a class="header-anchor" href="#_2-运行脚本"><span>2. 运行脚本</span></a></h5><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">python</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> script/run_dfa_pipeline_recommend.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h5 id="_3-结果输出" tabindex="-1"><a class="header-anchor" href="#_3-结果输出"><span>3. 结果输出</span></a></h5><p>脚本执行完毕后，控制台会打印执行的日志和最终执行状态，脚本运行后会在 <code>CACHE_DIR</code> 下生成 <code>my_pipeline.py</code>, <code>final_state.json</code> 和 <code>graph.png</code>。</p><h4 id="_3-3-实战-case-预训练数据清洗流水线" tabindex="-1"><a class="header-anchor" href="#_3-3-实战-case-预训练数据清洗流水线"><span>3.3 实战 Case：预训练数据清洗流水线</span></a></h4><p>你可以参考以下教程学习，也可以参考我们提供的<a href="https://colab.research.google.com/drive/1MMJxRpfYi7Zd-jc_pyhvM1Y2WoQXOFcu?usp=sharing" target="_blank" rel="noopener noreferrer">Google Colab</a>样例来运行：</p><p>假设我们有一个包含脏数据的预训练数据 <code>tests/test.jsonl</code>，我们希望清洗出一份高质量数据。打开脚本修改如下配置：</p><p><strong>场景配置：</strong></p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># ===== Example config (edit here) =====</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 1. 定义任务流程</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">TARGET</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">- 1.请帮我编排一个专门用于大规模预训练数据清洗的流水线，涵盖从去重、改写到质量过滤的全过程。  - 1. 请帮我编排一个专门用于大规模预训练数据清洗的流水线，涵盖从去重、改写到质量过滤的全过程。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">- 2. 在预训练阶段，原始的网页数据（如Common Crawl）往往充斥着大量的噪声、广告、乱码以及重复内容，数据质量参差不齐。我需要先做对原始数据做适当的改写，比如删除大量多余空格、html标签等。接着，需要通过基于规则的启发式过滤，把那些显而易见的垃圾文本、不完整文本和过短的无效数据剔除掉。同时，考虑到网络上内容复杂，我需要筛选指定语言的数据来训练大模型。网络数据的重复率很高，最好能通过模糊去重算法把相似的文档都清理掉，只保留一份。最后，为了保证模型学到的是高质量知识，我希望还能有一个质量分类模型，对清洗后的数据打分，只留下那些高教育价值的内容，从而构建一个高质量的预训练语料库。</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">- 3. 我需要一个专门处理海量预训练语料的端到端流水线。首先，你可以对原始文本进行基础的规范化处理，删除多余空格、html标签和表情符号。接着，利用启发式规则进行初步过滤，筛掉显着的低质量文本。这些启发式规则覆盖广泛，需要过滤掉符号/单词比例过高的文段、含敏感词的文段、单词数量异常的文段、以冒号/省略号结尾的不完整文段、语句数量异常的文段、空文本、平均单词长度异常的文段、含html标签的文段、无标点符号的文段、含特殊符号或水印的文段、括号比例过高的文段、大写字母比例过高的文段、含lorem ipsum（随机假文）的文段、独立单词比例过小的文段、字符数量较少的文段、以项目符号开头的文段和含有Javascript数量过多的文段。在此基础上，使用MinHash或类似算法进行文档级的模糊去重，大幅降低数据冗余。随后，利用训练好的质量评估模型对剩余数据进行打分和筛选。最后，还可以加入一个语言识别步骤，确保最终留下的都是目标语言的高质量纯净文本。</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 2. 指定测试数据路径</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">TEST_JSON_REL_PATH</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">tests/test.jsonl</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 3. 开启 Debug </span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">NEED_DEBUG</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;"> True</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">MAX_DEBUG_ROUNDS</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 5</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>运行：</strong> 运行脚本后，工作流会按以下步骤执行：</p><ol><li><strong>分析用户的数据和意图</strong>：分析用户的数据的特征。</li><li><strong>拆解用户任务，推荐算子</strong>：将用户的意图拆解成多个任务，检索匹配出与用户意图相关的算子。</li><li><strong>生成代码</strong>：分析需求顺序，串联这些算子，编写 pipeline 代码。</li><li><strong>自动测试</strong>：启动子进程试运行。如果出现了错误并启动了调试模式，Debugger Node 会尝试修复。</li><li><strong>最终交付</strong>：在成功执行或者达到最大调试轮数时结束工作流。</li></ol><p>用户可以在<code>CACHE_DIR</code>目录下找到生成的 Pipeline 代码文件和执行的日志文件。</p><h2 id="第二部分-pipeline-迭代优化-pipeline-refinement" tabindex="-1"><a class="header-anchor" href="#第二部分-pipeline-迭代优化-pipeline-refinement"><span>第二部分：Pipeline 迭代优化 (Pipeline Refinement)</span></a></h2><h3 id="_1-概述-1" tabindex="-1"><a class="header-anchor" href="#_1-概述-1"><span>1. 概述</span></a></h3><p>Pipeline 迭代优化 (Refinement) 允许用户通过自然语言对已生成的 DataFlow Pipeline 进行微调。用户无需手动修改复杂的 JSON 配置或 Python 代码，只需输入如“删除中间的过滤节点”等指令，系统便会智能解析意图并自动调整 Pipeline 的拓扑结构。</p><h3 id="_2-系统架构-1" tabindex="-1"><a class="header-anchor" href="#_2-系统架构-1"><span>2. 系统架构</span></a></h3><p>该功能由 <code>dataflow_agent/workflow/wf_pipeline_refine.py</code> 编排，采用 <strong>Analyzer -&gt; Planner -&gt; Refiner</strong> 的三段式架构：</p><h4 id="_2-1-refine-target-analyzer" tabindex="-1"><a class="header-anchor" href="#_2-1-refine-target-analyzer"><span>2.1 Refine Target Analyzer</span></a></h4><ul><li><strong>核心职责</strong>: <ul><li><strong>意图识别</strong>: 比较当前的 Pipeline 结构（<code>state.pipeline_structure_code</code>）和用户的自然语言需求（<code>target</code>），分析用户希望进行的修改类型（增、删、改）。</li><li><strong>RAG 预检索 (Pre-emptive RAG)</strong>: 这是关键特性。Analyzer 会解析出用户需求中隐含的子操作描述，并直接调用 RAG 搜索 <code>_get_operators_by_rag_with_scores</code>。它会计算相似度分数、评估匹配质量，并将最佳匹配的算子代码<code>code_snippet</code>和警告信息打包进 <code>op_contexts</code>。</li></ul></li><li><strong>输入</strong>: <code>state.pipeline_structure_code</code> (当前 pipeline 代码), <code>state.request.target</code> (用户修改指令)。</li><li><strong>输出</strong>: 包含 <code>needed_operators_desc</code> 的意图分析结果，以及包含丰富上下文的 <code>op_contexts</code>（算子代码、匹配度评分）。</li></ul><h4 id="_2-2-refine-planner" tabindex="-1"><a class="header-anchor" href="#_2-2-refine-planner"><span>2.2 Refine Planner</span></a></h4><ul><li><strong>职责</strong>: 基于 Analyzer 提供的意图和预检索到的算子上下文，制定具体的<strong>修改计划</strong>。它不直接修改代码，而是生成结构化的操作步骤。</li><li><strong>输入</strong>: Analyzer 的分析结果 (<code>intent</code>)、算子上下文 (<code>op_context</code>)、当前节点摘要。</li><li><strong>输出</strong>: 结构化的操作步骤列表，例如： <ul><li><code>REMOVE_NODE: node_filter_1</code></li><li><code>ADD_NODE: node_deduplicate (after node_loader)</code></li><li><code>UPDATE_EDGE: node_loader -&gt; node_deduplicate</code>。</li></ul></li></ul><h4 id="_2-3-json-pipeline-refiner" tabindex="-1"><a class="header-anchor" href="#_2-3-json-pipeline-refiner"><span>2.3 JSON Pipeline Refiner</span></a></h4><ul><li><strong>职责</strong>: 执行 Planner 的计划，直接操作 Pipeline 的 JSON 数据结构 Nodes 和 Edges。</li><li><strong>工具增强</strong>: 该 Agent 挂载了 <code>search_operator_by_description</code> 和 <code>get_operator_code_by_name</code> 作为后置工具。虽然 Analyzer 已经提供了 <code>op_context</code>，但如果 Refiner 在执行过程中发现信息不足，它仍可以主动发起搜索来补充算子信息。</li><li><strong>输出</strong>: 更新后的 <code>state.pipeline_structure_code</code>。</li></ul><h3 id="_3-使用指南-1" tabindex="-1"><a class="header-anchor" href="#_3-使用指南-1"><span>3. 使用指南</span></a></h3><p>本功能提供 <strong>图形界面 (Gradio UI)</strong> 和 <strong>命令行脚本</strong> 两种使用方式。</p><h4 id="_3-1-图形界面-1" tabindex="-1"><a class="header-anchor" href="#_3-1-图形界面-1"><span>3.1 图形界面</span></a></h4><p>集成在 <code>gradio_app/pages/pipeline_rec.py</code>，适合交互式探索和快速验证。启动 Web 界面：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">python gradio_app</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">/</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">app</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>访问 <code>http://127.0.0.1:7860</code> 开始使用</p><ol><li><strong>前提</strong>：必须先在页面上方点击 &quot;Generate Pipeline&quot; 生成初始 pipeline 代码，此时 <code>pipeline_json_state</code> 会被初始化。</li><li><strong>输入优化指令</strong>：在 &quot;优化需求&quot; 文本框中输入指令。</li><li><strong>执行优化</strong>：点击 <strong>&quot;Refine Pipeline&quot;</strong>。系统将显示更新后的 Python 代码、JSON 结构以及 Agent 的执行日志。</li><li><strong>历史回溯</strong>：使用 &quot;上一轮&quot; 和 &quot;下一轮&quot; 按钮在不同的优化版本间切换，查看代码演进过程。</li><li><strong>警告提示</strong>: 如果 RAG 匹配度较低，代码顶部会自动添加 <code>优化警告</code> 注释，提示用户当前生成的算子可能未完全匹配需求。</li></ol><h4 id="_3-2-脚本调用-1" tabindex="-1"><a class="header-anchor" href="#_3-2-脚本调用-1"><span>3.2 脚本调用</span></a></h4><p>使用 <code>script/run_dfa_pipeline_refine.py</code> 对已有的 Pipeline 结构进行微调。</p><h5 id="_1-修改配置-1" tabindex="-1"><a class="header-anchor" href="#_1-修改配置-1"><span>1. 修改配置</span></a></h5><p><strong>API 配置</strong></p><ul><li><strong><code>CHAT_API_URL</code></strong>: LLM 服务地址</li><li><strong><code>api_key</code></strong>: 访问密钥（使用环境变量 DF_API_KEY）</li><li><strong><code>MODEL</code></strong>: 模型名称，默认 gpt-4o</li></ul><p><strong>任务配置</strong></p><ul><li><strong><code>INPUT_JSON</code></strong>: 待优化的 Pipeline 结构文件路径</li><li><strong><code>OUTPUT_JSON</code></strong>: 优化后的 Pipeline JSON 结构文件保存路径</li><li><strong><code>TARGET</code></strong>: 用自然语言描述您希望如何修改 Pipeline <ul><li>示例：<code>&quot;请将Pipeline调整为只包含3个节点，简化数据流&quot;</code></li></ul></li></ul><h5 id="_2-运行脚本-1" tabindex="-1"><a class="header-anchor" href="#_2-运行脚本-1"><span>2. 运行脚本</span></a></h5><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">python</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> script/run_dfa_pipeline_refine.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="_3-3-实战-case-简化流水线" tabindex="-1"><a class="header-anchor" href="#_3-3-实战-case-简化流水线"><span>3.3 实战 Case：简化流水线</span></a></h4><p>你可以参考以下教程学习，也可以参考我们提供的<a href="https://colab.research.google.com/drive/1MMJxRpfYi7Zd-jc_pyhvM1Y2WoQXOFcu?usp=sharing" target="_blank" rel="noopener noreferrer">Google Colab</a>样例来运行：</p><p>假设上一步生成的流水线太复杂，包含了多余的“清洗”算子，我们希望将其移除来简化 Pipeline。</p><p><strong>场景配置：</strong></p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># ===== Example config (edit here) =====</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 1. 指定上一步生成的 Pipeline 结构文件</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">INPUT_JSON</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">dataflow_agent/tmps/pipeline.json</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 2. 下达修改指令</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">TARGET</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">请简化中间的清洗算子，简化数据流。</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 3. 指定结果保存位置</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">OUTPUT_JSON</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">cache_local/pipeline_refine_result.json.json</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>运行：</strong> Agent 会分析当前 Pipeline 的 JSON 拓扑结构，找到对应的去重节点，将其移除。</p>`,81)]))}const p=i(l,[["render",t]]),h=JSON.parse('{"path":"/zh/guide/agent/pipeline_rec_refine/","title":"智能 Pipeline 推荐与优化","lang":"zh-CN","frontmatter":{"title":"智能 Pipeline 推荐与优化","createTime":"2026/02/05 22:11:00","permalink":"/zh/guide/agent/pipeline_rec&refine/"},"readingTime":{"minutes":13.16,"words":3947},"git":{"createdTime":1770350470000,"updatedTime":1772083919000,"contributors":[{"name":"memoryforget","username":"memoryforget","email":"137028472+memoryforget@users.noreply.github.com","commits":3,"avatar":"https://avatars.githubusercontent.com/memoryforget?v=4","url":"https://github.com/memoryforget"},{"name":"Piar","username":"Piar","email":"2741277534@qq.com","commits":1,"avatar":"https://avatars.githubusercontent.com/Piar?v=4","url":"https://github.com/Piar"}]},"filePathRelative":"zh/notes/guide/agent/pipeline_rec&refine.md","headers":[]}');export{p as comp,h as data};
